{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a763c86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ae35e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_extract(path):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        :path: the absolute path to the specs\n",
    "        \n",
    "    Returns:\n",
    "        :spec_df: the dataframe for all processed specs\n",
    "        :corrupt_files: the corrupt files\n",
    "    \"\"\"\n",
    "    \n",
    "    # !pip3 install mammoth\n",
    "    \n",
    "    import os\n",
    "    import mammoth\n",
    "    import pandas as pd\n",
    "    from bs4 import BeautifulSoup\n",
    "    from pdfminer.high_level import extract_text\n",
    "    import re\n",
    "    import datetime\n",
    "\n",
    "    Rawtext, Jobtitle, Location, Education, Skills,\\\n",
    "    Experience, spec_identifier, corrupt_files = [], [], [], [], [], [], [], []\n",
    "\n",
    "    for sample_spec in os.listdir(path):\n",
    "        try:\n",
    "\n",
    "            ## Attach an identifier for the document\n",
    "            spec_identifier.append(sample_spec.split('.')[0])\n",
    "            #print(sample_spec)\n",
    "\n",
    "\n",
    "            ### Open and process the document\n",
    "            if re.search(\"docx\", sample_spec):\n",
    "                with open(path+\"/\"+sample_spec, \"rb\") as file:\n",
    "                    result = mammoth.convert_to_html(file)\n",
    "                    spec_html = result.value\n",
    "\n",
    "\n",
    "                spec_soup = BeautifulSoup(spec_html)\n",
    "                spec_text = spec_soup.get_text('\\n')\n",
    "\n",
    "                spec_split_lines = spec_text.splitlines()\n",
    "            else:\n",
    "                spec_text = extract_text(path+\"/\"+sample_spec)\n",
    "                spec_split_lines = spec_text.splitlines()\n",
    "\n",
    "            Rawtext.append(spec_text)\n",
    "\n",
    "            ## Extract jobtitle\n",
    "            job_name = \"\"\n",
    "            for line in spec_split_lines:\n",
    "                if re.search(\"Job Title\", line):\n",
    "                    start = line.find(\":\")\n",
    "                    job_name += line[start + 2:]\n",
    "                    #print(job_name)\n",
    "                    break\n",
    "\n",
    "            Jobtitle.append(job_name)\n",
    "\n",
    "\n",
    "            ## Extract loaction\n",
    "            area_name = \"\"\n",
    "            for line in spec_split_lines:\n",
    "                if re.search(\"Area\", line):\n",
    "                    start = line.find(\":\")\n",
    "                    area_name += line[start + 2:]\n",
    "                    #print(area_name)\n",
    "                    break\n",
    "\n",
    "            province_name = \"\"\n",
    "            for line in spec_split_lines:\n",
    "                if re.search(\"Province\", line):\n",
    "                    start = line.find(\":\")\n",
    "                    province_name += line[start + 2:]\n",
    "                    #print(province_name)\n",
    "                    break\n",
    "\n",
    "            location = area_name + \", \" + province_name\n",
    "\n",
    "            Location.append(location)\n",
    "\n",
    "\n",
    "            ## Extract education\n",
    "            possible_education_keywords = [\"Master\", \"diploma\", \"degree\", \"grade 12\"]\n",
    "\n",
    "            for line in spec_split_lines:\n",
    "                for edu_word in possible_education_keywords:\n",
    "                    if re.search(edu_word, line, re.IGNORECASE):\n",
    "                        Education.append(line)\n",
    "                        #print(line)\n",
    "                        break\n",
    "\n",
    "\n",
    "            ## Extract skills\n",
    "            skill_section_dividers = [\"What does it take\", \"Technology stack\", \"Skills\", \"Requirements\", \"Competencies\", \"Qualifications\", \"REQUIREMENTS\"]\n",
    "\n",
    "            for line in spec_split_lines:\n",
    "                for section in skill_section_dividers:\n",
    "                    if re.search(section, line, re.IGNORECASE):\n",
    "                        #print(line)\n",
    "                        #print(spec_split_lines.index(line))\n",
    "                        section_line = line\n",
    "                        #print(\"Found section \" + section)\n",
    "                        break\n",
    "\n",
    "            skills = []\n",
    "            section_index = spec_split_lines.index(section_line)\n",
    "            #print(section_index)\n",
    "            for line in spec_split_lines[section_index + 1:]:\n",
    "                skills.append(line)\n",
    "\n",
    "            Skills.append(skills)\n",
    "            #print(\"Found skills\")\n",
    "            #print(Skills[-1])\n",
    "\n",
    "            ## Extract experience\n",
    "            experience = []\n",
    "\n",
    "            for line in spec_split_lines:\n",
    "                if re.search(\"experience\", line, re.IGNORECASE):\n",
    "                    if re.search(\"year|years\", line, re.IGNORECASE):\n",
    "                        experience.append(line)\n",
    "\n",
    "            Experience.append(experience)\n",
    "\n",
    "        except Exception as e:\n",
    "\n",
    "            corrupt_files.append(sample_spec.split('.')[0])\n",
    "            #print(\"Found corrupted file\")\n",
    "            #print(e)\n",
    "\n",
    "            continue\n",
    "\n",
    "\n",
    "    spec_dict = {\"spec_identifier\": spec_identifier,\n",
    "                \"rawtext\": Rawtext,\n",
    "                \"jobtitle\": Jobtitle,\n",
    "                \"area\": Location,\n",
    "                \"education\": Education,\n",
    "                \"skills\": Skills,\n",
    "                \"experience\": Experience}\n",
    "\n",
    "    spec_df = pd.DataFrame(dict([(key, pd.Series(val)) for key, val in spec_dict.items()])).fillna(\"\")\n",
    "\n",
    "    spec_df[\"process_date\"] = datetime.datetime.now()\n",
    "\n",
    "    spec_df = spec_df[spec_df.rawtext!=\"\"]\n",
    "\n",
    "    return spec_df\n",
    "\n",
    "####====================================================================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "10d4ab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_identifier</th>\n",
       "      <th>rawtext</th>\n",
       "      <th>jobtitle</th>\n",
       "      <th>area</th>\n",
       "      <th>education</th>\n",
       "      <th>skills</th>\n",
       "      <th>experience</th>\n",
       "      <th>process_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7023</td>\n",
       "      <td>\\n\\n \\nClient Name:  Ashanti AI \\nJob Title: ...</td>\n",
       "      <td>Desktop Support Technician</td>\n",
       "      <td>Rosebank , Johannesburg</td>\n",
       "      <td>  Grade 12</td>\n",
       "      <td>[  Own transport ,   Willing to work overtim...</td>\n",
       "      <td>[  Minimum 2-3 years experience in a Desktop ...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7032</td>\n",
       "      <td>Client Name:  Engen\\nJob Title: Regional Manag...</td>\n",
       "      <td>Regional Manager</td>\n",
       "      <td>Somerset West, Western Cape</td>\n",
       "      <td>  Undergraduate degree or diploma in business...</td>\n",
       "      <td>[Experience working with email lists and datab...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7035</td>\n",
       "      <td>\\n\\n \\n\\nClient Name:  Bespoke \\nJob Title: D...</td>\n",
       "      <td>Developer</td>\n",
       "      <td>Blackheath , Cape Town</td>\n",
       "      <td>Bachelor’s Degree in Programming, Computer Sci...</td>\n",
       "      <td>[, ,   Must be able to effectively communicat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7027</td>\n",
       "      <td>\\n\\n \\nClient Name:  Bentok \\nJob Title: Juni...</td>\n",
       "      <td>Junior Server Administrator</td>\n",
       "      <td>Bloemfontein , Free State</td>\n",
       "      <td>Leadership/Management certification or diploma</td>\n",
       "      <td>[,   1 years’ experience. ,   Linux certific...</td>\n",
       "      <td>[  1 years’ experience. ]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7031</td>\n",
       "      <td>\\n\\n \\n\\nClient Name:  Sanlam \\nJob Title: Te...</td>\n",
       "      <td>Test Analyst</td>\n",
       "      <td>Durban , Kwazul Natal</td>\n",
       "      <td>IT related degree or diploma</td>\n",
       "      <td>[  Strong ability to work independently, whil...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7005</td>\n",
       "      <td>\\n\\n \\nClient Name:  ABSA \\nJob Title: Recrui...</td>\n",
       "      <td>Recruitment Specialist</td>\n",
       "      <td>Durbanville , Western Cape,</td>\n",
       "      <td>A BSc degree or relevant IT diploma.</td>\n",
       "      <td>[,   A stable, growing and innovative company...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7025</td>\n",
       "      <td>Client Name:  Bentok\\nJob Title: IT Executive:...</td>\n",
       "      <td>IT Executive: Customer &amp; Virtual Channels</td>\n",
       "      <td>Piet Retief\\t, Mpumalanga</td>\n",
       "      <td>  Degree in Procurement and Supply Chain or e...</td>\n",
       "      <td>[Stress tolerance, Decision- making, Problem s...</td>\n",
       "      <td>[8+ years’ management experience in an IT envi...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7020</td>\n",
       "      <td>Client Name:  Department of Sanitation\\nJob Ti...</td>\n",
       "      <td>Team Lead 3 - Wintel Tier 3</td>\n",
       "      <td>Bellville, Western Cape</td>\n",
       "      <td>  Degree in Computer Science (A must)</td>\n",
       "      <td>[Ability to work collaboratively within a team...</td>\n",
       "      <td>[Minimum 5 years leadership experience. , Mini...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7021</td>\n",
       "      <td>Client Name:  Explore AI\\nJob Title: Business ...</td>\n",
       "      <td>Business Analyst – BI User Interface Team</td>\n",
       "      <td>Bellville, Western Cape</td>\n",
       "      <td>BTech degree or diploma</td>\n",
       "      <td>[experience in designing websites, working wit...</td>\n",
       "      <td>[At least 2 years work experience as an analyst]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7022</td>\n",
       "      <td>\\nClient Name:  Explore AI \\nJob Title: Datab...</td>\n",
       "      <td>Database Administrator II</td>\n",
       "      <td>Bellville , Western Cape</td>\n",
       "      <td>A Master’s degree in management, monitoring an...</td>\n",
       "      <td>[o  You have a can do attitude , o  Can cope u...</td>\n",
       "      <td>[  3-5 Years’ experience as an Oracle DBA ]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7028</td>\n",
       "      <td>Client Name:  Bentok\\nJob Title: Developer\\nAr...</td>\n",
       "      <td>Developer</td>\n",
       "      <td>Kimberly\\t, Northern Cape</td>\n",
       "      <td>Matric or Grade 12 or NQF4</td>\n",
       "      <td>[A BSc degree or relevant IT diploma., A minim...</td>\n",
       "      <td>[A minimum of 3 years proven experience in dev...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7024</td>\n",
       "      <td>Client Name:  Ashanti AI\\nJob Title: Developer...</td>\n",
       "      <td>Developer/Analyst</td>\n",
       "      <td>Rosebank\\t, Gauteng</td>\n",
       "      <td>Information Technology - national diploma or b...</td>\n",
       "      <td>[Analytical mindset and logical thinker, Prefe...</td>\n",
       "      <td>[Preferably 4-6 years’ experience in PL/SQL or...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7010</td>\n",
       "      <td>\\n\\n \\nClient Name:  Bentok \\nJob Title: L2 P...</td>\n",
       "      <td>L2 Platform Engineer</td>\n",
       "      <td>Johannesburg, Cape Town , Gauteng, Western Cape</td>\n",
       "      <td>University degree in the field of computer sci...</td>\n",
       "      <td>[,   Moderate Azure and Infrastructure/WINTEL...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7019</td>\n",
       "      <td>\\n\\nClient Name:  Vodacom \\nJob Title: Procur...</td>\n",
       "      <td>Procurement Assistant</td>\n",
       "      <td>North West , North West</td>\n",
       "      <td>Honours Degree would be an advantage</td>\n",
       "      <td>[,   Degree in Procurement and Supply Chain o...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7015</td>\n",
       "      <td>Client Name:  Space X\\nJob Title: Full Stack A...</td>\n",
       "      <td>Full Stack Analyst Developer (C#, Angular)</td>\n",
       "      <td>Southern Suburbs, Western Cape</td>\n",
       "      <td>Talented UX Designer required in Rondebosch, o...</td>\n",
       "      <td>[Back End , Minimum 3 Years’ Experience, Micro...</td>\n",
       "      <td>[We are looking for Snr Full Stack Analyst Dev...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7034</td>\n",
       "      <td>\\n\\n \\n\\nClient Name:  Deloitte \\nJob Title: ...</td>\n",
       "      <td>Sales Admin</td>\n",
       "      <td>Montague Gardens , Cape Town</td>\n",
       "      <td>A diploma or equivalent in the design field</td>\n",
       "      <td>[,   Friendly and presentable ,   Experience...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7009</td>\n",
       "      <td>\\n\\n \\nClient Name:  ABSA \\nJob Title: Full S...</td>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Durbanville , Western Cape</td>\n",
       "      <td>  Bachelor’s Degree in Programming, Computer ...</td>\n",
       "      <td>[,   Degree in Computer Science (A must) , , ...</td>\n",
       "      <td>[  4 - 5 years’ experience  ]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7029</td>\n",
       "      <td>Client Name:  Bentok\\nJob Title: PL/SQL Develo...</td>\n",
       "      <td>PL/SQL Developers</td>\n",
       "      <td>Kimberly\\t, Northern Cape</td>\n",
       "      <td>Must have a Bachelor’s Degree with Accounting ...</td>\n",
       "      <td>[Ability to work under pressure, Deadline driv...</td>\n",
       "      <td>[Essential:  1-5 years’ working experience wit...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7011</td>\n",
       "      <td>\\n\\n \\nClient Name:  Bentok \\nJob Title: L3 P...</td>\n",
       "      <td>L3 Platform Engineer</td>\n",
       "      <td>Johannesburg, Cape Town , Gauteng, Western Cape</td>\n",
       "      <td>  Grade 12 Senior Certificate</td>\n",
       "      <td>[, ,   Advanced Azure and Infrastructure/WINT...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7008</td>\n",
       "      <td>Client Name: Nedbank\\nJob Title: Head of Divis...</td>\n",
       "      <td>Head of Division Strategic Information (SI)</td>\n",
       "      <td>Johannesburg, Gauteng</td>\n",
       "      <td></td>\n",
       "      <td>[Career Advice:, To apply for this position pl...</td>\n",
       "      <td>[Minimum of 10 years of progressively responsi...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7033</td>\n",
       "      <td>Client Name:  Deloitte\\nJob Title: Network Eng...</td>\n",
       "      <td>Network Engineer</td>\n",
       "      <td>East London, Eastern Cape</td>\n",
       "      <td></td>\n",
       "      <td>[Network administrator tools (WinSCP, Putty, W...</td>\n",
       "      <td>[Minimum of 5 years relevant technical experie...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7007</td>\n",
       "      <td>Client Name: Microsoft\\nJob Title: Information...</td>\n",
       "      <td>Information Security Officer (ISO) Area: Park ...</td>\n",
       "      <td>Information Security Officer (ISO) Area: Park ...</td>\n",
       "      <td></td>\n",
       "      <td>[University degree in the field of computer sc...</td>\n",
       "      <td>[3+ years’ security-related work experience,]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7013</td>\n",
       "      <td>\\n\\n \\nClient Name:  AUDI \\nJob Title: DevOps...</td>\n",
       "      <td>DevOps Engineer</td>\n",
       "      <td>Century City , Western Cape</td>\n",
       "      <td></td>\n",
       "      <td>[  Proven and demonstrable experience in part...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>7016</td>\n",
       "      <td>Client Name:  AUDI\\nJob Title: UX Designer \\nA...</td>\n",
       "      <td>UX Designer</td>\n",
       "      <td>Rondebosch, Western Cape</td>\n",
       "      <td></td>\n",
       "      <td>[ ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>7018</td>\n",
       "      <td>Client Name:  Vodacom\\nJob Title: Senior Engin...</td>\n",
       "      <td>Senior Engineer</td>\n",
       "      <td>Mpumalanga, Mpumalanga</td>\n",
       "      <td></td>\n",
       "      <td>[Should have A driver’s license and vehicle. ,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>7014</td>\n",
       "      <td>Client Name: Agility\\nJob Title: Software Deve...</td>\n",
       "      <td>Software Developer Area: Polokwane, South Afri...</td>\n",
       "      <td>Software Developer Area: Polokwane, South Afri...</td>\n",
       "      <td></td>\n",
       "      <td>[Proven and demonstrable experience in partici...</td>\n",
       "      <td>[4-7 years software development experience.]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7026</td>\n",
       "      <td>\\nClient Name:  Bentok \\nJob Title: IT Execut...</td>\n",
       "      <td>IT Executive: Customer &amp; Virtual Channels</td>\n",
       "      <td>Piet Retief , Mpumalanga</td>\n",
       "      <td></td>\n",
       "      <td>[  Stress tolerance ,   Decision- making , ...</td>\n",
       "      <td>[  8+ years’ management experience in an IT e...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7017</td>\n",
       "      <td>Client Name:  BCX\\nJob Title: IT Cabling\\nArea...</td>\n",
       "      <td>IT Cabling</td>\n",
       "      <td>Montague Gardens, Western Cape</td>\n",
       "      <td></td>\n",
       "      <td>[Time Management, Good business acumen]</td>\n",
       "      <td>[3 - 5 years professional cabling experience, ...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7003</td>\n",
       "      <td>Client Name: Unknown\\nJob Title: Assistant Fin...</td>\n",
       "      <td>Assistant Financial Accountant</td>\n",
       "      <td>Kwazulu Natal, Kwazulu Natal</td>\n",
       "      <td></td>\n",
       "      <td>[Must have a Bachelor’s Degree with Accounting...</td>\n",
       "      <td>[Five years progressive accounting experience,...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7012</td>\n",
       "      <td>\\n\\n \\nClient Name:  AUDI \\nJob Title: Level ...</td>\n",
       "      <td>Level 1 IT Technician</td>\n",
       "      <td>Umhlanga , Kwazul-Natal</td>\n",
       "      <td></td>\n",
       "      <td>[,  , , Development Plan. , ,  , , ]</td>\n",
       "      <td>[  2+ years of industry relevant Experience i...</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>7006</td>\n",
       "      <td>Client Name: Microsoft Job Title: Project mana...</td>\n",
       "      <td>Microsoft Job Title: Project manager Area: Tab...</td>\n",
       "      <td>Microsoft Job Title: Project manager Area: Tab...</td>\n",
       "      <td></td>\n",
       "      <td>[Analytical, Detail-oriented, Self-directed / ...</td>\n",
       "      <td>[2-5 years’ Project Management experience in IT]</td>\n",
       "      <td>2022-08-17 18:03:43.730038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spec_identifier                                            rawtext  \\\n",
       "0             7023   \\n\\n \\nClient Name:  Ashanti AI \\nJob Title: ...   \n",
       "1             7032  Client Name:  Engen\\nJob Title: Regional Manag...   \n",
       "2             7035   \\n\\n \\n\\nClient Name:  Bespoke \\nJob Title: D...   \n",
       "3             7027   \\n\\n \\nClient Name:  Bentok \\nJob Title: Juni...   \n",
       "4             7031   \\n\\n \\n\\nClient Name:  Sanlam \\nJob Title: Te...   \n",
       "5             7005   \\n\\n \\nClient Name:  ABSA \\nJob Title: Recrui...   \n",
       "6             7025  Client Name:  Bentok\\nJob Title: IT Executive:...   \n",
       "7             7020  Client Name:  Department of Sanitation\\nJob Ti...   \n",
       "8             7021  Client Name:  Explore AI\\nJob Title: Business ...   \n",
       "9             7022   \\nClient Name:  Explore AI \\nJob Title: Datab...   \n",
       "10            7028  Client Name:  Bentok\\nJob Title: Developer\\nAr...   \n",
       "11            7024  Client Name:  Ashanti AI\\nJob Title: Developer...   \n",
       "12            7010   \\n\\n \\nClient Name:  Bentok \\nJob Title: L2 P...   \n",
       "13            7019   \\n\\nClient Name:  Vodacom \\nJob Title: Procur...   \n",
       "14            7015  Client Name:  Space X\\nJob Title: Full Stack A...   \n",
       "15            7034   \\n\\n \\n\\nClient Name:  Deloitte \\nJob Title: ...   \n",
       "16            7009   \\n\\n \\nClient Name:  ABSA \\nJob Title: Full S...   \n",
       "17            7029  Client Name:  Bentok\\nJob Title: PL/SQL Develo...   \n",
       "18            7011   \\n\\n \\nClient Name:  Bentok \\nJob Title: L3 P...   \n",
       "19            7008  Client Name: Nedbank\\nJob Title: Head of Divis...   \n",
       "20            7033  Client Name:  Deloitte\\nJob Title: Network Eng...   \n",
       "21            7007  Client Name: Microsoft\\nJob Title: Information...   \n",
       "22            7013   \\n\\n \\nClient Name:  AUDI \\nJob Title: DevOps...   \n",
       "23            7016  Client Name:  AUDI\\nJob Title: UX Designer \\nA...   \n",
       "24            7018  Client Name:  Vodacom\\nJob Title: Senior Engin...   \n",
       "25            7014  Client Name: Agility\\nJob Title: Software Deve...   \n",
       "26            7026   \\nClient Name:  Bentok \\nJob Title: IT Execut...   \n",
       "27            7017  Client Name:  BCX\\nJob Title: IT Cabling\\nArea...   \n",
       "28            7003  Client Name: Unknown\\nJob Title: Assistant Fin...   \n",
       "29            7012   \\n\\n \\nClient Name:  AUDI \\nJob Title: Level ...   \n",
       "30            7006  Client Name: Microsoft Job Title: Project mana...   \n",
       "\n",
       "                                             jobtitle  \\\n",
       "0                         Desktop Support Technician    \n",
       "1                                    Regional Manager   \n",
       "2                                          Developer    \n",
       "3                       Junior Server Administrator     \n",
       "4                                      Test Analyst     \n",
       "5                            Recruitment Specialist     \n",
       "6           IT Executive: Customer & Virtual Channels   \n",
       "7                         Team Lead 3 - Wintel Tier 3   \n",
       "8           Business Analyst – BI User Interface Team   \n",
       "9                          Database Administrator II    \n",
       "10                                          Developer   \n",
       "11                                  Developer/Analyst   \n",
       "12                              L2 Platform Engineer    \n",
       "13                             Procurement Assistant    \n",
       "14         Full Stack Analyst Developer (C#, Angular)   \n",
       "15                                       Sales Admin    \n",
       "16                              Full Stack Developer    \n",
       "17                                  PL/SQL Developers   \n",
       "18                              L3 Platform Engineer    \n",
       "19       Head of Division Strategic Information (SI)    \n",
       "20                                  Network Engineer    \n",
       "21  Information Security Officer (ISO) Area: Park ...   \n",
       "22                                   DevOps Engineer    \n",
       "23                                       UX Designer    \n",
       "24                                    Senior Engineer   \n",
       "25  Software Developer Area: Polokwane, South Afri...   \n",
       "26         IT Executive: Customer & Virtual Channels    \n",
       "27                                         IT Cabling   \n",
       "28                     Assistant Financial Accountant   \n",
       "29                             Level 1 IT Technician    \n",
       "30  Microsoft Job Title: Project manager Area: Tab...   \n",
       "\n",
       "                                                 area  \\\n",
       "0                           Rosebank , Johannesburg     \n",
       "1                         Somerset West, Western Cape   \n",
       "2                             Blackheath , Cape Town    \n",
       "3                         Bloemfontein , Free State     \n",
       "4                             Durban , Kwazul Natal     \n",
       "5                        Durbanville , Western Cape,    \n",
       "6                          Piet Retief\\t, Mpumalanga    \n",
       "7                             Bellville, Western Cape   \n",
       "8                             Bellville, Western Cape   \n",
       "9                           Bellville , Western Cape    \n",
       "10                         Kimberly\\t, Northern Cape    \n",
       "11                               Rosebank\\t, Gauteng    \n",
       "12   Johannesburg, Cape Town , Gauteng, Western Cape    \n",
       "13                           North West , North West    \n",
       "14                     Southern Suburbs, Western Cape   \n",
       "15                      Montague Gardens , Cape Town    \n",
       "16                        Durbanville , Western Cape    \n",
       "17                         Kimberly\\t, Northern Cape    \n",
       "18   Johannesburg, Cape Town , Gauteng, Western Cape    \n",
       "19                              Johannesburg, Gauteng   \n",
       "20                          East London, Eastern Cape   \n",
       "21  Information Security Officer (ISO) Area: Park ...   \n",
       "22                       Century City , Western Cape    \n",
       "23                           Rondebosch, Western Cape   \n",
       "24                             Mpumalanga, Mpumalanga   \n",
       "25  Software Developer Area: Polokwane, South Afri...   \n",
       "26                         Piet Retief , Mpumalanga     \n",
       "27                     Montague Gardens, Western Cape   \n",
       "28                       Kwazulu Natal, Kwazulu Natal   \n",
       "29                           Umhlanga , Kwazul-Natal    \n",
       "30  Microsoft Job Title: Project manager Area: Tab...   \n",
       "\n",
       "                                            education  \\\n",
       "0                                          Grade 12    \n",
       "1     Undergraduate degree or diploma in business...   \n",
       "2   Bachelor’s Degree in Programming, Computer Sci...   \n",
       "3      Leadership/Management certification or diploma   \n",
       "4                        IT related degree or diploma   \n",
       "5                A BSc degree or relevant IT diploma.   \n",
       "6     Degree in Procurement and Supply Chain or e...   \n",
       "7               Degree in Computer Science (A must)    \n",
       "8                             BTech degree or diploma   \n",
       "9   A Master’s degree in management, monitoring an...   \n",
       "10                        Matric or Grade 12 or NQF4    \n",
       "11  Information Technology - national diploma or b...   \n",
       "12  University degree in the field of computer sci...   \n",
       "13               Honours Degree would be an advantage   \n",
       "14  Talented UX Designer required in Rondebosch, o...   \n",
       "15        A diploma or equivalent in the design field   \n",
       "16    Bachelor’s Degree in Programming, Computer ...   \n",
       "17  Must have a Bachelor’s Degree with Accounting ...   \n",
       "18                      Grade 12 Senior Certificate    \n",
       "19                                                      \n",
       "20                                                      \n",
       "21                                                      \n",
       "22                                                      \n",
       "23                                                      \n",
       "24                                                      \n",
       "25                                                      \n",
       "26                                                      \n",
       "27                                                      \n",
       "28                                                      \n",
       "29                                                      \n",
       "30                                                      \n",
       "\n",
       "                                               skills  \\\n",
       "0   [  Own transport ,   Willing to work overtim...   \n",
       "1   [Experience working with email lists and datab...   \n",
       "2   [, ,   Must be able to effectively communicat...   \n",
       "3   [,   1 years’ experience. ,   Linux certific...   \n",
       "4   [  Strong ability to work independently, whil...   \n",
       "5   [,   A stable, growing and innovative company...   \n",
       "6   [Stress tolerance, Decision- making, Problem s...   \n",
       "7   [Ability to work collaboratively within a team...   \n",
       "8   [experience in designing websites, working wit...   \n",
       "9   [o  You have a can do attitude , o  Can cope u...   \n",
       "10  [A BSc degree or relevant IT diploma., A minim...   \n",
       "11  [Analytical mindset and logical thinker, Prefe...   \n",
       "12  [,   Moderate Azure and Infrastructure/WINTEL...   \n",
       "13  [,   Degree in Procurement and Supply Chain o...   \n",
       "14  [Back End , Minimum 3 Years’ Experience, Micro...   \n",
       "15  [,   Friendly and presentable ,   Experience...   \n",
       "16  [,   Degree in Computer Science (A must) , , ...   \n",
       "17  [Ability to work under pressure, Deadline driv...   \n",
       "18  [, ,   Advanced Azure and Infrastructure/WINT...   \n",
       "19  [Career Advice:, To apply for this position pl...   \n",
       "20  [Network administrator tools (WinSCP, Putty, W...   \n",
       "21  [University degree in the field of computer sc...   \n",
       "22  [  Proven and demonstrable experience in part...   \n",
       "23                                                [ ]   \n",
       "24  [Should have A driver’s license and vehicle. ,...   \n",
       "25  [Proven and demonstrable experience in partici...   \n",
       "26  [  Stress tolerance ,   Decision- making , ...   \n",
       "27            [Time Management, Good business acumen]   \n",
       "28  [Must have a Bachelor’s Degree with Accounting...   \n",
       "29               [,  , , Development Plan. , ,  , , ]   \n",
       "30  [Analytical, Detail-oriented, Self-directed / ...   \n",
       "\n",
       "                                           experience  \\\n",
       "0   [  Minimum 2-3 years experience in a Desktop ...   \n",
       "1                                                  []   \n",
       "2                                                  []   \n",
       "3                          [  1 years’ experience. ]   \n",
       "4                                                  []   \n",
       "5                                                  []   \n",
       "6   [8+ years’ management experience in an IT envi...   \n",
       "7   [Minimum 5 years leadership experience. , Mini...   \n",
       "8    [At least 2 years work experience as an analyst]   \n",
       "9        [  3-5 Years’ experience as an Oracle DBA ]   \n",
       "10  [A minimum of 3 years proven experience in dev...   \n",
       "11  [Preferably 4-6 years’ experience in PL/SQL or...   \n",
       "12                                                 []   \n",
       "13                                                 []   \n",
       "14  [We are looking for Snr Full Stack Analyst Dev...   \n",
       "15                                                 []   \n",
       "16                     [  4 - 5 years’ experience  ]   \n",
       "17  [Essential:  1-5 years’ working experience wit...   \n",
       "18                                                 []   \n",
       "19  [Minimum of 10 years of progressively responsi...   \n",
       "20  [Minimum of 5 years relevant technical experie...   \n",
       "21      [3+ years’ security-related work experience,]   \n",
       "22                                                 []   \n",
       "23                                                 []   \n",
       "24                                                 []   \n",
       "25       [4-7 years software development experience.]   \n",
       "26  [  8+ years’ management experience in an IT e...   \n",
       "27  [3 - 5 years professional cabling experience, ...   \n",
       "28  [Five years progressive accounting experience,...   \n",
       "29  [  2+ years of industry relevant Experience i...   \n",
       "30   [2-5 years’ Project Management experience in IT]   \n",
       "\n",
       "                 process_date  \n",
       "0  2022-08-17 18:03:43.730038  \n",
       "1  2022-08-17 18:03:43.730038  \n",
       "2  2022-08-17 18:03:43.730038  \n",
       "3  2022-08-17 18:03:43.730038  \n",
       "4  2022-08-17 18:03:43.730038  \n",
       "5  2022-08-17 18:03:43.730038  \n",
       "6  2022-08-17 18:03:43.730038  \n",
       "7  2022-08-17 18:03:43.730038  \n",
       "8  2022-08-17 18:03:43.730038  \n",
       "9  2022-08-17 18:03:43.730038  \n",
       "10 2022-08-17 18:03:43.730038  \n",
       "11 2022-08-17 18:03:43.730038  \n",
       "12 2022-08-17 18:03:43.730038  \n",
       "13 2022-08-17 18:03:43.730038  \n",
       "14 2022-08-17 18:03:43.730038  \n",
       "15 2022-08-17 18:03:43.730038  \n",
       "16 2022-08-17 18:03:43.730038  \n",
       "17 2022-08-17 18:03:43.730038  \n",
       "18 2022-08-17 18:03:43.730038  \n",
       "19 2022-08-17 18:03:43.730038  \n",
       "20 2022-08-17 18:03:43.730038  \n",
       "21 2022-08-17 18:03:43.730038  \n",
       "22 2022-08-17 18:03:43.730038  \n",
       "23 2022-08-17 18:03:43.730038  \n",
       "24 2022-08-17 18:03:43.730038  \n",
       "25 2022-08-17 18:03:43.730038  \n",
       "26 2022-08-17 18:03:43.730038  \n",
       "27 2022-08-17 18:03:43.730038  \n",
       "28 2022-08-17 18:03:43.730038  \n",
       "29 2022-08-17 18:03:43.730038  \n",
       "30 2022-08-17 18:03:43.730038  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_df = spec_extract('specs')\n",
    "spec_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7741c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to create url search strings for recruiters' job specs\n",
    "\n",
    "def urlsearchstring(spec_df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        spec_df: is a spec dataframe\n",
    "            \n",
    "    Returns:\n",
    "        A list of LinkedIn and GitHub site search strings to be used for querying canduidates on linkedin\n",
    "        and github.\n",
    "    \"\"\"\n",
    "    ### Load the required packages\n",
    "    import urllib\n",
    "\n",
    "    ## Create a frame from the listed jobtitles in the spec dataframe\n",
    "\n",
    "    file = spec_df['jobtitle']\n",
    "    \n",
    "    ## Create a frame for the listed areas in the spec dataframe\n",
    "\n",
    "    #area = []\n",
    "    #for i in range(len(spec_df)):\n",
    "        #area.append(spec_df.area[i][0])\n",
    "    #area = pd.DataFrame(area)[0]\n",
    "    area = spec_df['area']\n",
    "    \n",
    "    \n",
    "    # Add the linkedin site search to the search string with restriction to SA\n",
    "    file_l = \"site:za.linkedin.com/in \" + file + \" \" + area\n",
    "\n",
    "    #### Parse the linkedin search string as a url and add to the URL search term (string).\n",
    "    file_l = file_l.apply(lambda x: urllib.parse.quote_plus(str(x)))\n",
    "    file_l1 = \"https://www.google.com/search?q=\" + file_l + ' &start=0'\n",
    "    file_l2 = \"https://www.google.com/search?q=\" + file_l + ' &start=10'\n",
    "    file_l3 = \"https://www.google.com/search?q=\" + file_l + ' &start=20'\n",
    "    \n",
    "    # Add the github site search to the search string without restriction to SA\n",
    "    file_g = \"github.com \" + file + \" followers \" + area\n",
    "    \n",
    "    #### Parse the github search string as a url and add to the URL search term (string).\n",
    "    file_g = file_g.apply(lambda x: urllib.parse.quote_plus(str(x)))\n",
    "    file_g1 = \"https://www.google.com/search?q=\" + file_g + ' &start=0'\n",
    "    file_g2 = \"https://www.google.com/search?q=\" + file_g + ' &start=10'\n",
    "    \n",
    "   \n",
    "    return file_l1, file_l2, file_l3, file_g1, file_g2\n",
    "\n",
    "\n",
    "#Function to get URLs of Google Search Results (GSR)\n",
    "\n",
    "def gsr_urls_scrapper(url, domain):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return the source code for the provided URL.\n",
    "        Args:\n",
    "            url (string): URL of the page to scrape.\n",
    "            searched_domain (tuple): domain one is searching result from.\n",
    "        Returns:\n",
    "            links (list): list of urls of Google Search Results (GSR).\n",
    "    \"\"\"\n",
    "    ### Load the required packages\n",
    "    import numpy as np\n",
    "    import requests\n",
    "    from requests_html import HTMLSession\n",
    "\n",
    "    try:\n",
    "        session = HTMLSession()\n",
    "        response = session.get(url)\n",
    "\n",
    "        links = list(response.html.absolute_links)\n",
    "\n",
    "        output = []\n",
    "        for link in links[:]:\n",
    "            if domain in link:\n",
    "                output.append(link)\n",
    "\n",
    "    except requests.exceptions.RequestException:\n",
    "         output = []\n",
    "\n",
    "    return np.unique(output).tolist()\n",
    "\n",
    "\n",
    "# Function to get LinkedIn GSR clean URLs\n",
    "\n",
    "def generate_gsr_urls(spec_df, qterm_func=urlsearchstring, gsr_scrapper_func=gsr_urls_scrapper):\n",
    "    \n",
    "    \"\"\"\n",
    "    Args:\n",
    "        df: input dataframe\n",
    "        gsr_urls_scrapper: function that scrapes the html source containing url links.\n",
    "        linkedin_query_term: function that generates the google search terms.\n",
    "    Returns:\n",
    "            dataframe with linkedIn  and Github urls for a given spec dataframe.\n",
    "\n",
    "    Usage:\n",
    "        generate_gsr_urls(spec_df)\n",
    "    \"\"\"\n",
    "    \n",
    "    ### Load required packages.\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    ### Get the the searched term URLs\n",
    "    linkedin_gs_terms1, linkedin_gs_terms2, linkedin_gs_terms3,\\\n",
    "    github_gs_terms1, github_gs_terms2 = qterm_func(spec_df)\n",
    "\n",
    "    out_dict_l = [] \n",
    "    out_dict_g = []\n",
    "\n",
    "    for spec_identifier, lgs_term1, lgs_term2, lgs_term3, ggs_term1, ggs_term2, spec_jobtitle\\\n",
    "    in zip(spec_df.spec_identifier, linkedin_gs_terms1, linkedin_gs_terms2,\\\n",
    "           linkedin_gs_terms3, github_gs_terms1, github_gs_terms2, spec_df.jobtitle):\n",
    "        \n",
    "\t# LinkedIn urls\n",
    "        lgsr_urls1 = gsr_scrapper_func(lgs_term1, \"za.linkedin.com\")\n",
    "        lgsr_urls2 = gsr_scrapper_func(lgs_term2, \"za.linkedin.com\")\n",
    "        lgsr_urls3 = gsr_scrapper_func(lgs_term3, \"za.linkedin.com\")\n",
    "        \n",
    "        url_identifier1 = [str(url).split(\"?\")[0] for url in lgsr_urls1]\n",
    "        url_identifier2 = [str(url).split(\"?\")[0] for url in lgsr_urls2]\n",
    "        url_identifier3 = [str(url).split(\"?\")[0] for url in lgsr_urls3]\n",
    "        url_identifier = url_identifier1 + url_identifier2 + url_identifier3\n",
    "        \n",
    "\n",
    "        out_dict_i = {\"spec_identifier\": [spec_identifier for i in range(len(url_identifier))],\n",
    "                     \"url_identifier\": np.unique(url_identifier).tolist(),\n",
    "                     \"spec_jobtitle\": [spec_jobtitle for i in range(len(url_identifier))]}\n",
    "\n",
    "        out_dict_l.append(pd.DataFrame(dict([(key, pd.Series(val)) for key, val in out_dict_i.items()])).fillna(\"\"))\n",
    "    \n",
    "\t## Github urls\n",
    "        ggsr_urls1 = gsr_scrapper_func(ggs_term1, \"github.com\")\n",
    "        ggsr_urls2 = gsr_scrapper_func(ggs_term2, \"github.com\")\n",
    "        urls_identifier1 = [str(url).split(\"?\")[0] for url in ggsr_urls1]\n",
    "        urls_identifier2 = [str(url).split(\"?\")[0] for url in ggsr_urls2]\n",
    "        urls_identifier = urls_identifier1 + urls_identifier2\n",
    "        \n",
    "        out_dict_g1 = {\"spec_identifier\": [spec_identifier for i in range(len(urls_identifier))],\n",
    "                     \"url_identifier\": np.unique(urls_identifier).tolist(),\n",
    "                     \"spec_jobtitle\": [spec_jobtitle for i in range(len(urls_identifier))]}\n",
    "\n",
    "        out_dict_g.append(pd.DataFrame(dict([(key, pd.Series(val)) for key, val in out_dict_g1.items()])).fillna(\"\"))\n",
    "\n",
    "\n",
    "    ## Concatenate and process LinkedIn urls    \n",
    "    out_df_l = pd.concat(out_dict_l, ignore_index=True) \n",
    "    out_df_l['url_identifier'] = out_df_l['url_identifier'].apply(lambda x:x if \"linkedin.com/in\" in x else \"\")\n",
    "    out_df_l = out_df_l[out_df_l['url_identifier']!=\"\"].reset_index(drop=True)\n",
    "\n",
    "\n",
    "    ## Concatenate and process Github urls\n",
    "    out_df_g = pd.concat(out_dict_g, ignore_index=True)\n",
    "    out_df_g['url_identifier'] = out_df_g['url_identifier'].apply(lambda x:x if \"https://github.com\" in x else \"\")\n",
    "    out_df_g = out_df_g[out_df_g['url_identifier']!=\"\"].reset_index(drop=True)\n",
    "    out_df_g['username'] = out_df_g.url_identifier.apply(lambda x: x.split(\"/\")[3] if \"https://github.com\" in x else \"\")\n",
    "\n",
    "    \n",
    "    return out_df_l, out_df_g\n",
    "\n",
    "    # ^ MAJOR IMPORTANT. NECESSARY FOR WEBSCRAPING FUNCTIONS TO WORK ^\n",
    "    # (requires spec df)\n",
    "    \n",
    "    \n",
    "#####===================================Extractor of a given LinkedIn or GitHub profile===========================================## \n",
    "from bs4 import BeautifulSoup\n",
    "from proxycrawl.proxycrawl_api import ProxyCrawlAPI\n",
    "    \n",
    "def profile_extractor(url): \n",
    "    \"\"\"\n",
    "    Description:\n",
    "    ------------\n",
    "        - url: [str], the url of a LinkedIn/GitHub profile page.\n",
    "        - The function returns the HTML code of the profile page.\n",
    "    \"\"\"\n",
    "\n",
    "    api = ProxyCrawlAPI({\"token\": \"4HJWW6aYgIyzjMfQQEHzbg\"})\n",
    "\n",
    "    response_profile = api.get(url)\n",
    "    profile_data = \"\"\n",
    "    if response_profile[\"status_code\"] == 200:\n",
    "        profile_data = BeautifulSoup(response_profile[\"body\"], \"html.parser\")\n",
    "\n",
    "    return profile_data\n",
    "\n",
    "# provided LinkedIn Extractor function\n",
    "\n",
    "def linkedin_extractor(linkedin_profile_url):\n",
    "    ' scraping LinkedIn profile & returns dictionary with profile attributes'\n",
    "    \n",
    "    import requests\n",
    "\n",
    "    api_endpoint = 'https://nubela.co/proxycurl/api/v2/linkedin'\n",
    "    #linkedin_profile_url = 'https://za.linkedin.com/in/craig-matthee-10b70825'  #linkedIn_urls.url_id[1]\n",
    "    api_key = 'a3673d04-e1f8-486d-9ac9-7eb013061462'\n",
    "    header_dic = {'Authorization': 'Bearer ' + api_key}\n",
    "\n",
    "    response = requests.get(api_endpoint,\n",
    "                          params={'url': linkedin_profile_url},\n",
    "                          headers=header_dic)\n",
    "\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "71eb613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linkedin_profile_extractor(linkedin_df, linkedin_extractor=linkedin_extractor):\n",
    "    \n",
    "    ''' extracting desired information from LinkedIn Extractor dictionary \n",
    "    \n",
    "    Args:\n",
    "        linkedin_df = dataframe (out_df_l) generated from generate_gsr_urls\n",
    "    Returns:\n",
    "        data frame with extractd info details for each LinkedIn url in input df\n",
    "    '''\n",
    "    \n",
    "    import pandas as pd                        \n",
    "    \n",
    "    linkedin_dataframe = []\n",
    "    \n",
    "    for i, j, k in zip(linkedin_df.spec_identifier, linkedin_df.url_identifier, linkedin_df.spec_jobtitle):\n",
    "        \n",
    "        \n",
    "        candidate_dict = linkedin_extractor(j)\n",
    "        \n",
    "        # generating dictionary of all the specs\n",
    "        clean_dict = {}\n",
    "\n",
    "        # Spec identifier\n",
    "        clean_dict['spec_identifier'] = i\n",
    "        \n",
    "        # Spec jobtitle\n",
    "        clean_dict['spec_jobtitle'] = k\n",
    "        \n",
    "        # name\n",
    "        clean_dict['name'] = candidate_dict['full_name']\n",
    "\n",
    "        # job title\n",
    "        clean_dict['job title'] = candidate_dict['occupation']\n",
    "\n",
    "        # area\n",
    "        city = candidate_dict['city']\n",
    "        state = candidate_dict['state']\n",
    "        country = candidate_dict['country']\n",
    "        clean_dict['area'] = str(f'{city}, {state}, {country}')\n",
    "\n",
    "        # education\n",
    "        degree_list = []\n",
    "        for edu in candidate_dict['education']:\n",
    "            degree_list.append(edu['degree_name'])\n",
    "        clean_dict['education'] = degree_list\n",
    "\n",
    "        # experience\n",
    "        job_list = []\n",
    "        for job in candidate_dict['experiences']:\n",
    "            job_list.append(job['title'])\n",
    "        clean_dict['experience'] = job_list\n",
    "\n",
    "        # skills / experience description\n",
    "        # summary & descriptions of experiences will include skills & experience\n",
    "            # skills section of LinkedIn Profile not included in scrapper code\n",
    "        description_list = []\n",
    "        description_list.append(candidate_dict['summary'])\n",
    "        for job in candidate_dict['experiences']:\n",
    "            description_list.append(job['description'])\n",
    "        clean_dict['skills'] = description_list\n",
    "\n",
    "        \n",
    "        linkedin_dataframe.append(pd.DataFrame(clean_dict, index=range(1)))\n",
    "        \n",
    "\n",
    "        # note: industry hard to categorize\n",
    "    \n",
    "    return pd.concat(linkedin_dataframe, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "6248755d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:143: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spec_identifier</th>\n",
       "      <th>url_identifier</th>\n",
       "      <th>spec_jobtitle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [spec_identifier, url_identifier, spec_jobtitle]\n",
       "Index: []"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linkedin_df, github_df = generate_gsr_urls(spec_df.head(3))\n",
    "linkedin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1e39b8cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    https://www.google.com/search?q=site%3Aza.link...\n",
       " dtype: object,\n",
       " 0    https://www.google.com/search?q=site%3Aza.link...\n",
       " dtype: object,\n",
       " 0    https://www.google.com/search?q=site%3Aza.link...\n",
       " dtype: object,\n",
       " 0    https://www.google.com/search?q=github.com+Des...\n",
       " dtype: object,\n",
       " 0    https://www.google.com/search?q=github.com+Des...\n",
       " dtype: object)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = urlsearchstring(spec_df.head(1))\n",
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7584ce38",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_list = []\n",
    "s = ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec316d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(job_name, occupation, education, degree_list, skills_found, description_list):\n",
    "\n",
    "    #Job Title\n",
    "    cat1 = [job_name, occupation]\n",
    "    job_matrix = cv.fit_transform(cat1)\n",
    "    jobPercentage = cosine_similarity(job_matrix)[0][1] * 40 \n",
    "    \n",
    "    #Education\n",
    "    cat2 = [education, s.join(degree_list)]\n",
    "    edu_matrix = cv.fit_transform(cat2)\n",
    "    eduPercentage = cosine_similarity(job_matrix)[0][1] * 30 \n",
    "    \n",
    "    #Skills\n",
    "    cat2 = [s.join(skills_found), s.join(description_list)]\n",
    "    skl_matrix = cv.fit_transform(cat2)\n",
    "    sklPercentage = cosine_similarity(skl_matrix)[0][1] * 30\n",
    "    \n",
    "    #Summing the scores\n",
    "    score = jobPercentage + eduPercentage + sklPercentage\n",
    "    score = round(score, 2)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589efda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing accuracy \n",
    "job_name = \"Information Analyst\"\n",
    "occupation = \"Information Analyst\"\n",
    "education = \"Bachelor's or PHD\"\n",
    "degree_list = [\"Bachelor's\", \"PHD\"]\n",
    "skills_found = [\"R\", \"SQL\", \"analytical skills\"]\n",
    "description_list = [\"R\", \"SQL\", \"analytical skills\"]\n",
    "\n",
    "\n",
    "scores_list.append(score(job_name, occupation, education, degree_list, skills_found, description_list))\n",
    "print(scores_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139506d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
